{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8f15d8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:01.452137Z",
     "start_time": "2021-09-10T13:22:56.553680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"data/mnist/\"\n",
    "train_data = pd.read_csv(data_path + 'train.csv')\n",
    "test_data = pd.read_csv(data_path + 'test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "03110ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:01.545884Z",
     "start_time": "2021-09-10T13:23:01.455128Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = train_data.drop('label', axis=1).to_numpy(), train_data['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d72c6ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:01.561842Z",
     "start_time": "2021-09-10T13:23:01.548877Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digit(x_set, y_set, idx):\n",
    "    img = x_set[idx].reshape(28,28)\n",
    "    plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "    plt.title('true label: %d' % y_set.T[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b311c867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:01.749342Z",
     "start_time": "2021-09-10T13:23:01.563838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(X, y, idx = 41575)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "28e94bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:01.970748Z",
     "start_time": "2021-09-10T13:23:01.752334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 4132]\n",
      " [   1 4684]\n",
      " [   2 4177]\n",
      " [   3 4351]\n",
      " [   4 4072]\n",
      " [   5 3795]\n",
      " [   6 4137]\n",
      " [   7 4401]\n",
      " [   8 4063]\n",
      " [   9 4188]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4132., 4684., 4177., 4351., 4072., 3795., 4137., 4401., 4063.,\n",
       "        4188.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "283d6ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:17:47.901421Z",
     "start_time": "2021-09-09T22:17:47.381532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([8., 8.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image augmentation\n",
    "from PIL import Image\n",
    "\n",
    "def transform_image(x_set, y_set, idx, show=False):\n",
    "    #print(x_set[idx].shape)\n",
    "    img = x_set[idx].reshape(28,28)\n",
    "    im = Image.fromarray(np.uint8(img))\n",
    "    ds = [2, 4]\n",
    "    ims = []\n",
    "    for d in ds:\n",
    "        im = Image.fromarray(np.uint8(img))\n",
    "        im = im.resize((28 + 2 * d, 28), Image.ANTIALIAS)\n",
    "        im = im.crop((d, 0, 28 + d, 28))\n",
    "        im = np.asarray(im)\n",
    "        ims.append(im)\n",
    "    if(show):\n",
    "        fig, ax = plt.subplots(1, len(ds) + 1)\n",
    "        ax[0].imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "        ax[0].set_title('Before label: %d' % y_set.T[idx])\n",
    "        for i in range(len(ims)):\n",
    "            ax[i + 1].imshow(ims[i], cmap='Greys',  interpolation='nearest')\n",
    "            ax[i + 1].set_title('After d=%d' % ds[i])\n",
    "        plt.show()\n",
    "    ims = np.array([im.flatten() for im in ims])\n",
    "    #print(ims.shape)\n",
    "    return ims, y_set.T[idx] * np.ones(len(ims))\n",
    "\n",
    "transform_image(X, y, idx = 10, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3f22c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:47:08.747521Z",
     "start_time": "2021-09-09T19:57:49.410115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "[[0.0000e+00 1.2396e+04]\n",
      " [1.0000e+00 1.4052e+04]\n",
      " [2.0000e+00 1.2531e+04]\n",
      " [3.0000e+00 1.3053e+04]\n",
      " [4.0000e+00 1.2216e+04]\n",
      " [5.0000e+00 1.1385e+04]\n",
      " [6.0000e+00 1.2411e+04]\n",
      " [7.0000e+00 1.3203e+04]\n",
      " [8.0000e+00 1.2189e+04]\n",
      " [9.0000e+00 1.2564e+04]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([12396., 14052., 12531., 13053., 12216., 11385., 12411., 13203.,\n",
       "        12189., 12564.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_dataset(X, Y):\n",
    "    X_res, y_res = X, Y\n",
    "    for idx in range(len(X)):\n",
    "        if(idx % 1000 == 0):\n",
    "            print(idx)\n",
    "        x0, y0 = transform_image(X, y, idx = idx)\n",
    "        X_res = np.append(X_res, x0, axis=0)\n",
    "        y_res = np.append(y_res, y0, axis=0)\n",
    "    return X_res, y_res\n",
    "X2, y2 = transform_dataset(X, y)\n",
    "unique, counts = np.unique(y2, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "plt.hist(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "494fd78c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:47:08.873189Z",
     "start_time": "2021-09-09T21:47:08.751515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126000, 784) (126000,)\n"
     ]
    }
   ],
   "source": [
    "# Check result\n",
    "plot_digit(X2, y2, idx = -1)\n",
    "print(X2.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e0c254e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:05.325341Z",
     "start_time": "2021-09-10T13:23:05.315329Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y = enc.fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "093d7bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:05.901346Z",
     "start_time": "2021-09-10T13:23:05.748756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7372549 , 1.        , 0.36862746,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.7490196 ,\n",
       "       0.98039216, 0.99215686, 0.3647059 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.48235294, 0.972549  , 0.99215686, 0.654902  ,\n",
       "       0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3137255 , 0.96862745,\n",
       "       0.99215686, 0.8156863 , 0.05098039, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.11372549, 0.8117647 , 0.99215686, 0.92156863, 0.3019608 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.21176471, 0.81960785, 0.99215686,\n",
       "       0.99215686, 0.34509805, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.3647059 ,\n",
       "       0.99607843, 0.99215686, 0.93333334, 0.6666667 , 0.06666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.8235294 , 0.99607843, 0.99215686,\n",
       "       0.62352943, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.81960785,\n",
       "       0.99215686, 0.99607843, 0.9411765 , 0.31764707, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10588235, 0.99215686, 0.99215686, 0.99607843,\n",
       "       0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.07843138, 0.80784315,\n",
       "       0.99607843, 0.99607843, 0.7764706 , 0.02745098, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.65882355, 0.99215686, 0.99215686, 0.76862746,\n",
       "       0.02745098, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.07843138, 0.79607844,\n",
       "       0.99215686, 0.972549  , 0.29803923, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.08627451, 0.7372549 , 0.99215686, 0.9607843 , 0.3647059 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.40392157, 0.99215686,\n",
       "       0.99215686, 0.7490196 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.34901962, 0.9411765 , 0.99215686, 0.7647059 , 0.09803922,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05882353, 0.8627451 , 0.99215686,\n",
       "       0.99215686, 0.3137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.36862746, 0.99215686, 0.99215686, 0.99215686, 0.36862746,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34901962, 0.9843137 ,\n",
       "       0.99215686, 0.98039216, 0.5137255 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8392157 , 0.85490197, 0.37254903,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "X = X.astype('float32') / 255.0\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "425ba5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:23:09.056326Z",
     "start_time": "2021-09-10T13:23:08.588578Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "62c97ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:19:24.658012Z",
     "start_time": "2021-09-10T13:19:24.579224Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5e04d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:19:30.778662Z",
     "start_time": "2021-09-10T13:19:30.760710Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "#from keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8047fda",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d89f5d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:10:52.795333Z",
     "start_time": "2021-09-09T22:10:52.745707Z"
    }
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "input_size = X_train.shape[1]\n",
    "num_labels = 10\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "192835d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:10:53.278244Z",
     "start_time": "2021-09-09T22:10:53.199838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-1ea66cdba2f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py:1665 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643848c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:12.340850Z",
     "start_time": "2021-09-08T17:56:12.023697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9769\n",
      "\n",
      "Test accuracy: 97.7%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93564370",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61a430b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:34:07.863853Z",
     "start_time": "2021-09-06T20:34:07.818384Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24f6dac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:32:24.569591Z",
     "start_time": "2021-09-10T13:32:24.559618Z"
    }
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "dropout = 0.45\n",
    "input_size = X_train.shape[1]\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f43c3bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:32:25.985185Z",
     "start_time": "2021-09-10T13:32:25.924305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6aa27429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:30:06.653593Z",
     "start_time": "2021-09-10T13:29:11.054580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.4064 - accuracy: 0.8728 - val_loss: 0.1783 - val_accuracy: 0.9468\n",
      "Epoch 2/20\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.1761 - accuracy: 0.9455 - val_loss: 0.1490 - val_accuracy: 0.9574\n",
      "Epoch 3/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1315 - accuracy: 0.9589 - val_loss: 0.1221 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.1051 - accuracy: 0.9664 - val_loss: 0.1104 - val_accuracy: 0.9701\n",
      "Epoch 5/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0952 - accuracy: 0.9698 - val_loss: 0.1077 - val_accuracy: 0.9698\n",
      "Epoch 6/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0819 - accuracy: 0.9733 - val_loss: 0.1055 - val_accuracy: 0.9709\n",
      "Epoch 7/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0730 - accuracy: 0.9767 - val_loss: 0.1106 - val_accuracy: 0.9720\n",
      "Epoch 8/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0616 - accuracy: 0.9800 - val_loss: 0.0972 - val_accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0590 - accuracy: 0.9802 - val_loss: 0.1043 - val_accuracy: 0.9749\n",
      "Epoch 10/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0558 - accuracy: 0.9817 - val_loss: 0.0968 - val_accuracy: 0.9749\n",
      "Epoch 11/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0525 - accuracy: 0.9830 - val_loss: 0.1002 - val_accuracy: 0.9770\n",
      "Epoch 12/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.1125 - val_accuracy: 0.9746\n",
      "Epoch 13/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 0.1059 - val_accuracy: 0.9759\n",
      "Epoch 14/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.1085 - val_accuracy: 0.9743\n",
      "Epoch 15/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 0.1192 - val_accuracy: 0.9772\n",
      "Epoch 16/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.1096 - val_accuracy: 0.9772\n",
      "Epoch 17/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.1123 - val_accuracy: 0.9765\n",
      "Epoch 18/20\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.1068 - val_accuracy: 0.9749\n",
      "Epoch 19/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.1120 - val_accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.1184 - val_accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b6cae8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:30:31.010865Z",
     "start_time": "2021-09-10T13:30:30.861218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22c8bcfb670>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "71bff9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:40:39.737953Z",
     "start_time": "2021-09-10T13:33:59.466314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.5198 - accuracy: 0.8374\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.93 - 1s 5ms/step - loss: 0.2299 - accuracy: 0.9310\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9476\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9543\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9602\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9647\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0955 - accuracy: 0.9698\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0798 - accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0754 - accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0722 - accuracy: 0.9762\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 0.9782\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9797\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0650 - accuracy: 0.9789\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9801\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9813\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9816\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0540 - accuracy: 0.9822\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9834\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.5142 - accuracy: 0.8399\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.9331\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9488\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1234 - accuracy: 0.9634\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9651\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9686\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9695\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9728\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0787 - accuracy: 0.9749\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9755\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0714 - accuracy: 0.9776\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9778\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0657 - accuracy: 0.9792\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 0.9793\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9820\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0546 - accuracy: 0.9828\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0531 - accuracy: 0.9830\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9836\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5195 - accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9324\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1739 - accuracy: 0.9479\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9552\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1294 - accuracy: 0.9604\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9644\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9690\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9692\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9710\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0822 - accuracy: 0.9740\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0779 - accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9784\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0642 - accuracy: 0.9793\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9803\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9808\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9797\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0525 - accuracy: 0.9832\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9820\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5189 - accuracy: 0.8392\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9313\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9466\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9601\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9651\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9685\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9693\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9729\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9739\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9766\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0664 - accuracy: 0.9787\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0670 - accuracy: 0.9790\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9793\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9812\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0570 - accuracy: 0.9817\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9819\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9831\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_122 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.5311 - accuracy: 0.8346\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2289 - accuracy: 0.9302\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1722 - accuracy: 0.9483\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9618\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9647\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9663\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9711\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9726\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9730\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9769\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9785\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0631 - accuracy: 0.9797\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9806\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9812\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9809\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9809\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9835\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5179 - accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2278 - accuracy: 0.9311\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9561\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9612\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1147 - accuracy: 0.9650\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9678\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9703\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9733\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9735\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9754\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9770\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 0.9801\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.9796\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0583 - accuracy: 0.9805\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9820\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9808\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9820\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9831\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5072 - accuracy: 0.8433\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2264 - accuracy: 0.9318\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1715 - accuracy: 0.9486\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9563\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9601\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9653\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9679\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9707\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9733\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9738\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9767\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9761\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9778\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9789\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9794\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9797\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9819\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9832\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.98 - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9831\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5181 - accuracy: 0.8381\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2263 - accuracy: 0.9314\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9563\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9624\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9656\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9692\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9690\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9719\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9740\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9761\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9766\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9779\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9799\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.98 - 1s 5ms/step - loss: 0.0589 - accuracy: 0.9810\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0582 - accuracy: 0.9808\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9822\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9829\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0562 - accuracy: 0.9815\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5214 - accuracy: 0.8366\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9296\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9481\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9552\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9600\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9641\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9685\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9718\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9740\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0787 - accuracy: 0.9742\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9761\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0700 - accuracy: 0.9770\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9785\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9786\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9794\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9796\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9822\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9821\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5178 - accuracy: 0.8375\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9329\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9456\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9547\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9605\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9670\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9735\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0832 - accuracy: 0.9738\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9753\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9772\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9780\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9801\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9796\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9806\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9801\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9824\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9822\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9828\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5215 - accuracy: 0.8355\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2268 - accuracy: 0.9314\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9450\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9553\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9613\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9665\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9684\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0921 - accuracy: 0.9709\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9719\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9738\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9759\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9768\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9779\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9793\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9797\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9806\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9811\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9805\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9816\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9829\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5100 - accuracy: 0.8406\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2247 - accuracy: 0.9320\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1723 - accuracy: 0.9481\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9618\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9647\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9694\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9719\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9741\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9747\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9775\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9784\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9795\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0645 - accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9801\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9816\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9832\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9831\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9824\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_146 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.5276 - accuracy: 0.8346\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2317 - accuracy: 0.9304\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9471\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9558\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9615\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9659\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9679\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9726\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0804 - accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9761\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 0.9765\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9798\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0650 - accuracy: 0.9790\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9807\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9817\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9808\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9820\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9834\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.5136 - accuracy: 0.8395\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.9341\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1737 - accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9557\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1251 - accuracy: 0.9610\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9661\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1023 - accuracy: 0.9684\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0960 - accuracy: 0.9704\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9729\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9746\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0739 - accuracy: 0.9770\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9770\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.9774\n",
      "Epoch 14/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 0.9799\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9794\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0570 - accuracy: 0.9812\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9824\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0556 - accuracy: 0.9815\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9833\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_152 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.5195 - accuracy: 0.8378\n",
      "Epoch 2/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2246 - accuracy: 0.9317\n",
      "Epoch 3/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1749 - accuracy: 0.9463\n",
      "Epoch 4/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.9563\n",
      "Epoch 5/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1247 - accuracy: 0.9617\n",
      "Epoch 6/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.9642\n",
      "Epoch 7/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9679\n",
      "Epoch 8/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9705\n",
      "Epoch 9/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9718\n",
      "Epoch 10/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9745\n",
      "Epoch 11/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9751\n",
      "Epoch 12/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9769\n",
      "Epoch 13/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9782\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9789\n",
      "Epoch 15/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 0.9803\n",
      "Epoch 16/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9803\n",
      "Epoch 17/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0554 - accuracy: 0.9825\n",
      "Epoch 18/20\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0569 - accuracy: 0.9818\n",
      "Epoch 19/20\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0538 - accuracy: 0.9824\n",
      "Epoch 20/20\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "n = 15\n",
    "for i in range(n):\n",
    "    model = define_model()\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=batch_size)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6f49275e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:41:30.341132Z",
     "start_time": "2021-09-10T13:41:26.521835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 15\n",
    "y_pred = np.zeros((y_test.shape[0], 10))\n",
    "for i in range(n):\n",
    "    y_pred = y_pred + models[i].predict(X_test)\n",
    "y_pred = y_pred / n\n",
    "\n",
    "y_true = y_test\n",
    "y_true = np.argmax(y_true, axis=1).T\n",
    "y_pred = np.argmax(y_pred, axis=1).T\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fa587698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:43:05.816067Z",
     "start_time": "2021-09-10T13:43:05.800074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802380952380952"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "88365fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:28:46.889442Z",
     "start_time": "2021-09-10T13:28:46.739842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9750\n",
      "\n",
      "Test accuracy: 97.5%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11f6358f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:12:30.259340Z",
     "start_time": "2021-09-09T22:12:30.249387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12600, 784)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaa548",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1110a1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:36:02.993203Z",
     "start_time": "2021-09-06T20:36:02.983230Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "afe6fc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:36:03.576948Z",
     "start_time": "2021-09-06T20:36:03.563982Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test2 = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ba9a04c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:29:30.957038Z",
     "start_time": "2021-09-06T20:26:47.328857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kam\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "329/329 [==============================] - 7s 21ms/step - loss: 0.3240 - accuracy: 0.9022\n",
      "Epoch 2/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.1319 - accuracy: 0.9610\n",
      "Epoch 3/20\n",
      "329/329 [==============================] - 8s 23ms/step - loss: 0.0891 - accuracy: 0.9745\n",
      "Epoch 4/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0684 - accuracy: 0.9803\n",
      "Epoch 5/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0561 - accuracy: 0.9837\n",
      "Epoch 6/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0457 - accuracy: 0.9867\n",
      "Epoch 7/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0398 - accuracy: 0.9887 0s\n",
      "Epoch 8/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0330 - accuracy: 0.9907\n",
      "Epoch 9/20\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.0286 - accuracy: 0.9922\n",
      "Epoch 10/20\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.99 - 9s 27ms/step - loss: 0.0264 - accuracy: 0.9927\n",
      "Epoch 11/20\n",
      "329/329 [==============================] - 9s 28ms/step - loss: 0.0224 - accuracy: 0.9940\n",
      "Epoch 12/20\n",
      "329/329 [==============================] - 9s 26ms/step - loss: 0.0187 - accuracy: 0.9954\n",
      "Epoch 13/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0164 - accuracy: 0.9960\n",
      "Epoch 14/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 15/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0124 - accuracy: 0.9978\n",
      "Epoch 16/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 17/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0097 - accuracy: 0.9982\n",
      "Epoch 18/20\n",
      "329/329 [==============================] - 8s 26ms/step - loss: 0.0086 - accuracy: 0.9985\n",
      "Epoch 19/20\n",
      "329/329 [==============================] - 8s 25ms/step - loss: 0.0075 - accuracy: 0.9989\n",
      "Epoch 20/20\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0069 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e8074c070>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = define_model()\n",
    "model.fit(X_train2, y_train, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "08fb0f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:29:31.817616Z",
     "start_time": "2021-09-06T20:29:30.957038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9996\n",
      "\n",
      "Test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test2, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e931e8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:42:56.110871Z",
     "start_time": "2021-09-06T20:42:54.453303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 2s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "\n",
      "Test accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test2, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5eb0",
   "metadata": {},
   "source": [
    "# PCA + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2b8bb38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:56:19.822005Z",
     "start_time": "2021-09-06T20:55:16.025765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e81a9b9d0>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = np.arange(5, 200, 5)\n",
    "explanations = []\n",
    "for n in n_components:\n",
    "    pca = PCA(n_components = n)\n",
    "    pca.fit(X_train)\n",
    "    X_train3 = pca.transform(X_train)\n",
    "    explanations.append(sum(pca.explained_variance_ratio_))\n",
    "plt.plot(n_components, explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7a98c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T20:57:26.080037Z",
     "start_time": "2021-09-06T20:57:24.572174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344250716385432"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 125\n",
    "pca = PCA(n_components = n_features)\n",
    "pca.fit(X_train)\n",
    "X_train3 = pca.transform(X_train)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7a091334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T21:01:37.889376Z",
     "start_time": "2021-09-06T21:01:37.846452Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test3 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3ff774cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T21:00:21.432935Z",
     "start_time": "2021-09-06T21:00:07.526662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 256)               32256     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 100,618\n",
      "Trainable params: 100,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.5605 - accuracy: 0.8255\n",
      "Epoch 2/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9194\n",
      "Epoch 3/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9382\n",
      "Epoch 4/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1671 - accuracy: 0.9484\n",
      "Epoch 5/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9543\n",
      "Epoch 6/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9587\n",
      "Epoch 7/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.9631\n",
      "Epoch 8/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.1088 - accuracy: 0.9656\n",
      "Epoch 9/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9690\n",
      "Epoch 10/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9707\n",
      "Epoch 11/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.9720\n",
      "Epoch 12/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9723\n",
      "Epoch 13/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9747\n",
      "Epoch 14/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9756\n",
      "Epoch 15/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.9762\n",
      "Epoch 16/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9773\n",
      "Epoch 17/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9777\n",
      "Epoch 18/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9792\n",
      "Epoch 19/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9802\n",
      "Epoch 20/20\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e80e56f40>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network parameters\n",
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "dropout = 0.45\n",
    "input_size = X_train3.shape[1]\n",
    "num_labels = 10\n",
    "def define_model():\n",
    "    # model is a 3-layer MLP with ReLU and dropout after each layer\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = define_model()\n",
    "model.fit(X_train3, y_train, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5a18f9d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T21:01:46.065584Z",
     "start_time": "2021-09-06T21:01:45.828711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9964\n",
      "\n",
      "Test accuracy: 99.6%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test3, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3b986",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1be7e3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:43:51.321046Z",
     "start_time": "2021-09-10T13:43:51.304091Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res = test_data.to_numpy()\n",
    "X_res2 = X_res.reshape((X_res.shape[0], 28, 28, 1))\n",
    "#X_res3 = pca.transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a6be8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:31:15.483888Z",
     "start_time": "2021-09-10T13:31:13.045409Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ea45225f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:31:16.574064Z",
     "start_time": "2021-09-10T13:31:16.562058Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ee04ecf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:44:43.557909Z",
     "start_time": "2021-09-10T13:44:43.453174Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = y_pred\n",
    "np.savetxt(\"mnist.csv\", np.dstack((np.arange(1, arr.size+1),arr))[0],\"%d,%d\",header=\"ImageId,Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61032e",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aea963a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:30:44.015428Z",
     "start_time": "2021-09-09T22:30:43.950951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2d98097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:39:19.628273Z",
     "start_time": "2021-09-09T22:30:44.771566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.6270 - accuracy: 0.7969\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.2537 - accuracy: 0.9251\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1986 - accuracy: 0.9423\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9492\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1513 - accuracy: 0.9570\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1313 - accuracy: 0.9613\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1178 - accuracy: 0.9644\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1106 - accuracy: 0.9672\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.1065 - accuracy: 0.9672\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9707\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9712\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9726\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.9746\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 0.0832 - accuracy: 0.9754\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9765\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9761\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9778\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9780\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9798\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9791\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9810\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9804\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9806\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9817\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0593 - accuracy: 0.9814\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9822\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9828\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9838\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9841\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9844\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9837\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9843\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9844\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9855\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9855\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9850\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9854\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9861\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9868\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0412 - accuracy: 0.9872\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9757\n",
      "Score for fold 1: loss of 0.11811786890029907; accuracy of 97.57142663002014%\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.6237 - accuracy: 0.7986\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9252\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9409\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9490\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9543\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.9596\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9649\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9658\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.1063 - accuracy: 0.9677\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9701\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9711\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0903 - accuracy: 0.9726\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9739\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9750\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9741\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9777\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9760\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9787\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9798\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9798\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0670 - accuracy: 0.9800\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9819\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9812\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9822\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9818\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9823\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9828\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9842\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9839\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9836\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9839\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9831\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9838\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9848\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9871\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9854\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9857\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9869\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9862\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9798\n",
      "Score for fold 2: loss of 0.09158051759004593; accuracy of 97.97618985176086%\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.6215 - accuracy: 0.7970\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.9247\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1983 - accuracy: 0.9411\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9489\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9556\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1344 - accuracy: 0.9611\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9628\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9675\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9698\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1006 - accuracy: 0.9701\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9724\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9722\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9744\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9746\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9769\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9757\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9782\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0701 - accuracy: 0.9781\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 0.9796\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9796\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9806\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9802\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9813\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0597 - accuracy: 0.9810\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0566 - accuracy: 0.9824\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9837\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9827\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0517 - accuracy: 0.9842\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9834\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9845\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0535 - accuracy: 0.9841\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9839\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9852\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0459 - accuracy: 0.9858\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9851\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9853\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9846\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9865\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.9856\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 0.9863\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9845\n",
      "Score for fold 3: loss of 0.07124399393796921; accuracy of 98.45238327980042%\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.6194 - accuracy: 0.8003\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.9234\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2018 - accuracy: 0.9407\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9511\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1504 - accuracy: 0.9551\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9604\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1228 - accuracy: 0.9628\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9680\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9672\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9703\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9716\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9714\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9756\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9752\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9764\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9769\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9789\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9787\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9803\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9807\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9806\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9805\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9808\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9816\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9817\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9830\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0536 - accuracy: 0.9834\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9842\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9838\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0534 - accuracy: 0.9836\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9855\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9847\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9843\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9847\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9853\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9863\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9862\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9847\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9869\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9867\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9817\n",
      "Score for fold 4: loss of 0.08015745133161545; accuracy of 98.16666841506958%\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.6261 - accuracy: 0.7982\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.9242\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2029 - accuracy: 0.9415\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1711 - accuracy: 0.9497\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1483 - accuracy: 0.9569\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9612\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9632\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9668\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9674\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9700\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9730\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0869 - accuracy: 0.9737\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9734\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9751\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9753\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0805 - accuracy: 0.9757\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0747 - accuracy: 0.9778\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9790\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9792\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9805\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9798\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9807\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9809\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9817\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9827\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9826\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9825\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9830\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9847\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9837\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9842\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9845\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0501 - accuracy: 0.9844\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9836\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9861\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9851\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9861\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9849\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9870\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0469 - accuracy: 0.9854\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9767\n",
      "Score for fold 5: loss of 0.0845889002084732; accuracy of 97.66666889190674%\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.6181 - accuracy: 0.8016\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2551 - accuracy: 0.9253\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9406\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9517\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1507 - accuracy: 0.9546\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1374 - accuracy: 0.9599\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9636\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9671\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9684\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9718\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9724\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9740\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9729\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9760\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9779\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9780\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9777\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9784\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9787\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9802\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9811\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9808\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9821\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9823\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9831\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9824\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9820\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9845\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9843\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9842\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9839\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9850\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9854\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9852\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9850\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9863\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9864\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9865\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9866\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.98 - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9875\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9790\n",
      "Score for fold 6: loss of 0.0892869308590889; accuracy of 97.90475964546204%\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.6174 - accuracy: 0.8014\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9229\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2056 - accuracy: 0.9402\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9499\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1510 - accuracy: 0.9553\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9591\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9625\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9643\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9674\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9696\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9715\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9724\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9731\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9738\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9763\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0760 - accuracy: 0.9766\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9786\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9785\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9793\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9802\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9803\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9816\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 0.9817\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9816\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9827\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0531 - accuracy: 0.9828\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9823\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9825\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0544 - accuracy: 0.9841\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9830\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9856\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9840\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9842\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9844\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9855\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9858\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9852\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9858\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9861\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9855\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9798\n",
      "Score for fold 7: loss of 0.07596695423126221; accuracy of 97.97618985176086%\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.6180 - accuracy: 0.8004\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9232\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9411\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1680 - accuracy: 0.9516\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9567\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.1337 - accuracy: 0.9598\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9634\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.1136 - accuracy: 0.9658\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.1073 - accuracy: 0.9667\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0990 - accuracy: 0.9709\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0968 - accuracy: 0.9703\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9734\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0868 - accuracy: 0.9739\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0840 - accuracy: 0.9744\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9762\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9768\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.9757\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9783\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9774\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0663 - accuracy: 0.9796\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9812\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9807\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9807\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9815\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0561 - accuracy: 0.9831\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9841\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0582 - accuracy: 0.9821\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9829\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9815\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9848\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9842\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9843\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9845\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9845\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9863\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9851\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9854\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 2s 6ms/step - loss: 0.0436 - accuracy: 0.9865\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9872\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0431 - accuracy: 0.9863\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9795\n",
      "Score for fold 8: loss of 0.08449892699718475; accuracy of 97.95238375663757%\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 4ms/step - loss: 0.6358 - accuracy: 0.7937\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2603 - accuracy: 0.9232\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9397\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9496\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9535\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9616\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9639\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.1123 - accuracy: 0.9663\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1089 - accuracy: 0.9669\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9696\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0952 - accuracy: 0.9713\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0954 - accuracy: 0.9721\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9732\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9748\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0832 - accuracy: 0.9757\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9766\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9768\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9799\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9784\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9783\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9794\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.9815\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9806\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9808\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9837\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9817\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9833\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9814\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0531 - accuracy: 0.9834\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9837\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9838\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0510 - accuracy: 0.9842\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0483 - accuracy: 0.9841\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9861\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9847\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9861\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9863\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9866\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9802\n",
      "Score for fold 9: loss of 0.08821834623813629; accuracy of 98.02380800247192%\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/40\n",
      "296/296 [==============================] - 2s 5ms/step - loss: 0.6048 - accuracy: 0.8043\n",
      "Epoch 2/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.2526 - accuracy: 0.9266\n",
      "Epoch 3/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1954 - accuracy: 0.9432\n",
      "Epoch 4/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1710 - accuracy: 0.9501\n",
      "Epoch 5/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9565\n",
      "Epoch 6/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1316 - accuracy: 0.9605\n",
      "Epoch 7/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9641\n",
      "Epoch 8/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9665\n",
      "Epoch 9/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9684\n",
      "Epoch 10/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9707\n",
      "Epoch 11/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9715\n",
      "Epoch 12/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9722\n",
      "Epoch 13/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9734\n",
      "Epoch 14/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9750\n",
      "Epoch 15/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0791 - accuracy: 0.9757\n",
      "Epoch 16/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9768\n",
      "Epoch 17/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0651 - accuracy: 0.9803\n",
      "Epoch 18/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9773\n",
      "Epoch 19/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9786\n",
      "Epoch 20/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9792\n",
      "Epoch 21/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9799\n",
      "Epoch 22/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9812\n",
      "Epoch 23/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0593 - accuracy: 0.9815\n",
      "Epoch 24/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9815\n",
      "Epoch 25/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9828\n",
      "Epoch 26/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9820\n",
      "Epoch 27/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9832\n",
      "Epoch 28/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9844\n",
      "Epoch 29/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9836\n",
      "Epoch 30/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9841\n",
      "Epoch 31/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9834\n",
      "Epoch 32/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9842\n",
      "Epoch 33/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9853\n",
      "Epoch 34/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9848\n",
      "Epoch 35/40\n",
      "296/296 [==============================] - 1s 5ms/step - loss: 0.0483 - accuracy: 0.9849\n",
      "Epoch 36/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9873\n",
      "Epoch 37/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9848\n",
      "Epoch 38/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9868\n",
      "Epoch 39/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 40/40\n",
      "296/296 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9863\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9760\n",
      "Score for fold 10: loss of 0.10320931673049927; accuracy of 97.59523868560791%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 10\n",
    "batch_size = 128\n",
    "no_epochs = 40\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "models = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    model = define_model()\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(X[train], y[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs)\n",
    "    models.append(model)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X[test], y[test])\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e400c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:39:19.644150Z",
     "start_time": "2021-09-09T22:39:19.630188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.9285717010498"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ba26539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:39:19.660108Z",
     "start_time": "2021-09-09T22:39:19.646146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(acc_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed2e814a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T22:39:50.415902Z",
     "start_time": "2021-09-09T22:39:50.411920Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_per_fold[2]\n",
    "model = models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "982fbd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:30:55.036326Z",
     "start_time": "2021-09-10T13:30:54.688746Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = np.argmax(y_true, axis=1).T\n",
    "y_pred = np.argmax(y_pred, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4480387a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T13:30:56.087564Z",
     "start_time": "2021-09-10T13:30:55.351530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True,cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf8335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
